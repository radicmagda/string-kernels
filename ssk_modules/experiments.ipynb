{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering performace of an SVM classifier (OVR scheme) for 4 classes, using three different kernel functions. To train and test the SVM classifier we'll have to provide it with the similarity matrices.\n",
    "\n",
    "Training - requires NxN Gram matrix (square matrix compromised of values of the kernel function between pairs training examples)\n",
    "\n",
    "Testing - requires MxN matrix (element i,j is the value of the kernel function between i-th example of the testing set and j-th example of the training set)\n",
    "\n",
    "N = cardinaliry of the training set, M = cardinality of the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(first_dataset, second_dataset, similarity_function, symmetrical=False):\n",
    "    \"\"\"\n",
    "    Calculate the similarity matrix between elements of two datasets using a similarity function.\n",
    "\n",
    "    Args:\n",
    "    - first_dataset: List or array-like, the first dataset\n",
    "    - second_dataset: List or array-like, the second dataset\n",
    "    - similarity_function: Function, the similarity function that takes two elements as arguments\n",
    "\n",
    "    Returns:\n",
    "    - similarity_matrix: NumPy ndarray, the similarity matrix\n",
    "    \"\"\"\n",
    "    if(symmetrical):\n",
    "        size = len(first_dataset)\n",
    "        similarity_matrix = [[0.0] * size for _ in range(size)]\n",
    "\n",
    "        for i in range(size):\n",
    "            for j in range(i, size):\n",
    "                value =similarity_function(first_dataset[i], second_dataset[j])\n",
    "                similarity_matrix[i][j] = value\n",
    "                similarity_matrix[j][i] = value \n",
    "    else:\n",
    "        similarity_matrix = [[similarity_function(x, y) for y in second_dataset] for x in first_dataset]\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering SSK, NGK and WK kernel functions, each with its own set of hiperparameters. \n",
    "\n",
    "SSK is parameterised by $k$ = length of the substrings used for feature mapping/kernel computation and $\\lambda$= real numer from the interval [0,1] which indicates how much we penalise the noncontiguity of the appeared substring in the imput document. \n",
    "\n",
    "NGK is parameterised with $n$, corresponding to $k$ in SSk.\n",
    "\n",
    "WK has no hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def WK_SVM(X_train, y_train, X_test, y_test):  #a multi-class classifier\n",
    "\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using linear tfidf mapping\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, use_idf=True, smooth_idf=True, norm='l2',\n",
    "                                 analyzer='word', stop_words='english')\n",
    "\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    results_df = pd.DataFrame({\n",
    "    'Kernel' : 'WK',\n",
    "    'Class': range(len(precision)),\n",
    "    'F1-Score': f1,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    })\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def NGK_SVM(X_train, y_train, X_test, y_test, k):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using linear n-gram mapping\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the ngrams\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    ngram_range = (k, k)\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=ngram_range)\n",
    "\n",
    "    x_train_ngrams = normalize(vectorizer.fit_transform(X_train), norm='l2')  #ngram vectors normalised to l2 norm\n",
    "    x_test_ngrams = normalize(vectorizer.transform(X_test), norm='l2')\n",
    "\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(x_train_ngrams, y_train)\n",
    "\n",
    "    y_pred = svm_classifier.predict(x_test_ngrams)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'NGK',\n",
    "        'k':k,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import sskpy\n",
    "def ssk(a, b, k, lambd):\n",
    "    if(k==0 or lambd==0):\n",
    "        return 0\n",
    "    else:\n",
    "        return sskpy(a,b,k,lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssk_partial(ka, Lambda):\n",
    "    return lambda a,b: ssk(a,b,k=ka, lambd=Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_SVM(X_train, y_train, X_test, y_test, k, lambd ):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using SSK\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the substrings, lambd= weight decay factor\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k,lambd, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    kernel_function=ssk_partial(k, lambd)\n",
    "    train_matrix=similarity_matrix(X_train, X_train, kernel_function, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, kernel_function)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK',\n",
    "        'k':k,\n",
    "        'lambda': lambd,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.Creating datasets\n",
    "each run has to be repeated 10 times - we need 10 pairs of (train, test) sets that need to satisfy the properties given in the paper:\n",
    "\n",
    " earn 152 (40); acq 114 (25); crude 76 (15); grain 38 (10)\n",
    " since not enough examples of corn I'll use grain as the 4th topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('../data/preprocessed.csv')[['topics', 'body']].copy()\n",
    "topic_mapping = {'earn': 0, 'acq': 1, 'crude': 2, 'grain': 3}\n",
    "data['topics'] = data['topics'].map(topic_mapping)\n",
    "\n",
    "N_classes=3\n",
    "n_per_class=50\n",
    "\n",
    "class0df=data[data.topics==0].head(n_per_class)  #earn\n",
    "class1df=data[data.topics==1].head(n_per_class)  #acq\n",
    "class2df=data[data.topics==2].head(n_per_class)  #crude\n",
    "class3df=data[data.topics==3].head(n_per_class)  #grain\n",
    "\n",
    "final=pd.concat([class0df, class1df, class2df, class3df][:N_classes])\n",
    "print(len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_all=np.array(final['body'])\n",
    "y_all=np.array(final['topics'])\n",
    "\n",
    "n_folds = 5\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "datasets = []\n",
    "\n",
    "for train_index, test_index in stratified_kfold.split(X_all,y_all):\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    \n",
    "    datasets.append((X_train, X_test, y_train, y_test))\n",
    "\n",
    "# datasets[i] = Xtrain_ i , Xtest_i, ytrain_i, ytest_i, i=1,...,10 aka the index of the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Varying Subsequence Length in SSK and NGK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experimet we're keeping lambda for SSK at 0.5, and varying k/n for SSK/NGKin values [3,4,5,6,7,8,10,12], WK has no parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17748/3051937657.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mcsv_filename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"exp1_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mresults1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"data/{csv_filename}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\magda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3561\u001b[0m         )\n\u001b[0;32m   3562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3563\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3564\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3565\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\magda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         )\n\u001b[1;32m-> 1180\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\magda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \"\"\"\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\magda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;31m# Only for write methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\magda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mfr\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "lambda_default=0.5\n",
    "kvalues=[3,4,5,6,7,8,10,12]\n",
    "\n",
    "experiment_results=[]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    Xtrain, Xtest, ytrain, ytest= datasets[i]\n",
    "\n",
    "    wk_results=WK_SVM(Xtrain,ytrain, Xtest,ytest)\n",
    "    experiment_results.append(wk_results)\n",
    "\n",
    "    for k in kvalues:\n",
    "        ngk_results=NGK_SVM(Xtrain,ytrain, Xtest,ytest,k)\n",
    "        ssk_results=SSK_SVM(Xtrain,ytrain, Xtest,ytest,k, lambda_default)\n",
    "        experiment_results.append(ngk_results)\n",
    "        experiment_results.append(ssk_results)\n",
    "\n",
    "results1=pd.concat(experiment_results)\n",
    "\n",
    "\n",
    "csv_filename=f\"exp1_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results1.to_csv(f\"../data/{csv_filename}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Varying Weight Decay Factor in SSK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment we're keeping k/n for SSK/NGK at 5 and varying lambda for SSK trough values [0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12756/4239466042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlambdavalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0msske2_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSSK_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrainexp2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrainexp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtestexp2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytestexp2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk_default\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mexp2_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msske2_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12756/137249822.py\u001b[0m in \u001b[0;36mSSK_SVM\u001b[1;34m(X_train, y_train, X_test, y_test, k, lambd)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# calculate gram matrix for training and matrix for prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mkernel_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mssk_partial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymmetrical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtest_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12756/1309353465.py\u001b[0m in \u001b[0;36msimilarity_matrix\u001b[1;34m(first_dataset, second_dataset, similarity_function, symmetrical)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msimilarity_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12756/3429591623.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mssk_partial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mka\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mssk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mka\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12756/3207864371.py\u001b[0m in \u001b[0;36mssk\u001b[1;34m(a, b, k, lambd)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msskpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\magda\\Desktop\\diplomski-1.sem\\uuzop\\uuzop_projekt\\ssk_modules\\main.py\u001b[0m in \u001b[0;36msskpy\u001b[1;34m(a, b, k, lam)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msskpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mssk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_default=5\n",
    "lambdavalues=[0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7]\n",
    "\n",
    "exp2_results=[]\n",
    "\n",
    "for i_exp2 in range(len(datasets)):\n",
    "    Xtrainexp2, Xtestexp2, ytrainexp2, ytestexp2= datasets[i_exp2]\n",
    "\n",
    "    wke2_results=WK_SVM(Xtrainexp2,ytrainexp2, Xtestexp2,ytestexp2)\n",
    "    exp2_results.append(wke2_results)\n",
    "\n",
    "    ngke2_results=NGK_SVM(Xtrainexp2,ytrainexp2, Xtestexp2,ytestexp2,k_default)\n",
    "    exp2_results.append(ngke2_results)\n",
    "\n",
    "    for l in lambdavalues:\n",
    "        sske2_results=SSK_SVM(Xtrainexp2,ytrainexp2, Xtestexp2,ytestexp2,k_default, l)\n",
    "        exp2_results.append(sske2_results)\n",
    "\n",
    "\n",
    "results2=pd.concat(exp2_results)\n",
    "\n",
    "\n",
    "csv2_filename=f\"exp2_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results2.to_csv(f\"../data/{csv2_filename}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 - Combining two SSK of Different Substring Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we're examining the performance of the SVM classifier using a kernel that is computed as the sum of two SSK with differnt lenths k1 and k2. \n",
    "\n",
    "We're keeping labmda constant for both of those at 0.5 and looking at combinations of lengths in [(3,0),(4,0),(5,0),(6,0),(3,4),(3,5),(3,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_k_comb_SVM(X_train, y_train, X_test, y_test, k1, k2,lambd ):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using SSK\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the substrings, lambd= weight decay factor\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k,lambd, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    kernel1=ssk_partial(k1, lambd)\n",
    "    kernel2=ssk_partial(k2, lambd)\n",
    "    comb= lambda x,y: kernel1(x,y) + kernel2(x,y)\n",
    "    train_matrix=similarity_matrix(X_train, X_train, comb, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, comb)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK k comb',\n",
    "        'k':f\"({k1}, {k2})\",\n",
    "        'lambda': lambd,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_default=0.5\n",
    "k1k2s=[(3,4),(3,5),(3,6)]\n",
    "exp3_results=[]\n",
    "\n",
    "for i3 in range(len(datasets)):\n",
    "    Xtrain3, Xtest3, ytrain3, ytest3= datasets[i3]\n",
    "\n",
    "    for k1,k2 in k1k2s:\n",
    "        kcomb_results=SSK_k_comb_SVM(Xtrain3,ytrain3, Xtest3,ytest3,k1,k2, lambda_default)\n",
    "        exp3_results.append(kcomb_results)\n",
    "\n",
    "results3=pd.concat(exp3_results)\n",
    "\n",
    "\n",
    "csv_filename3=f\"exp3_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results3.to_csv(f\"../data/{csv_filename3}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 - Combining SSK and NGK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're examining the performance of the weighted sum of NGK and SSK with same length.\n",
    "\n",
    "Length of both kernels =5, lambda for SSK=0.5, varying the contibutions of NGK and SSK in[(1,0), (0,1), (0.5, 0.5), (0.6,0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def ngk(x,y, trained_vectoriser):\n",
    "    x_ngrams = normalize(trained_vectoriser.transform([x]).toarray(), norm='l2')  \n",
    "    y_ngrams = normalize(trained_vectoriser.transform([y]).toarray(), norm='l2')\n",
    "    return np.dot(x_ngrams.flatten(), y_ngrams.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def SSK_NGK_SVM(X_train, y_train, X_test, y_test, wngk,wssk,k, lambd ):\n",
    "    # define kernel function based on given parameters\n",
    "\n",
    "    sskkernel=ssk_partial(k, lambd)\n",
    "    \n",
    "    if(k !=0):                    \n",
    "        vectorizer = CountVectorizer(analyzer='char', ngram_range=(k,k))\n",
    "        vectorizer.fit(X_train)\n",
    "        ngkkernel=lambda x,y : ngk(x,y,vectorizer)\n",
    "    else:\n",
    "        ngkkernel=lambda x,y : 0\n",
    "\n",
    "    comb= lambda x,y: wssk*sskkernel(x,y) + wngk* ngkkernel(x,y)\n",
    "\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    train_matrix=similarity_matrix(X_train, X_train, comb, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, comb)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK NGK comb',\n",
    "        'wngk, wssk':f\"({wngk}, {wssk})\",\n",
    "        'k': k,\n",
    "        'lambda': lambd,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_default=5\n",
    "lambda_default=0.5\n",
    "wnwss=[(1,0), (0,1), (0.5, 0.5), (0.6,0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]\n",
    "exp4_results=[]\n",
    "\n",
    "for i4 in range(len(datasets)):\n",
    "    Xtrain4, Xtest4, ytrain4, ytest4= datasets[i4]\n",
    "\n",
    "    for wn,ws in wnwss:\n",
    "        ssk_ngk_comb_results=SSK_NGK_SVM(Xtrain4,ytrain4, Xtest4, ytest4,wn, ws,k_default, lambda_default)\n",
    "        exp4_results.append(ssk_ngk_comb_results)\n",
    "\n",
    "results4=pd.concat(exp4_results)\n",
    "\n",
    "csv_filename4=f\"exp4_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results4.to_csv(f\"../data/{csv_filename4}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 - Combining two SSK of Different Weight Decay Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here were using a kernel that is a sum of two SSK with different lambdas, and same k=5. \n",
    "The lambda values were varied trough [(0.05,0), (0.5,0), (0.05, 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_lambd_comb_SVM(X_train, y_train, X_test, y_test, k, lambd1,lambd2 ):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using SSK\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the substrings, lambd= weight decay factor\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k,lambd, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    kernel1=ssk_partial(k, lambd1)\n",
    "    kernel2=ssk_partial(k, lambd2)\n",
    "    comb= lambda x,y: kernel1(x,y) + kernel2(x,y)\n",
    "    train_matrix=similarity_matrix(X_train, X_train, comb, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, comb)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK lambda comb',\n",
    "        'k': k,\n",
    "        'lambdas': f'{lambd1},{lambd2}',\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_default=5\n",
    "l1l2s=[(0.05,0), (0.5,0), (0.05, 0.5)]\n",
    "\n",
    "exp5_results=[]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    Xtrain, Xtest, ytrain, ytest= datasets[i]\n",
    "\n",
    "    for l1,l2 in l1l2s:\n",
    "        lcomb_results=SSK_lambd_comb_SVM(Xtrain,ytrain, Xtest,ytest,k_default,l1,l2)\n",
    "        exp5_results.append(lcomb_results)\n",
    "\n",
    "results5=pd.concat(exp5_results)\n",
    "\n",
    "\n",
    "csv_filename5=f\"exp5_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results5.to_csv(f\"../data/{csv_filename5}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
