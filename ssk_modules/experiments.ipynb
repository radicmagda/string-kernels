{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering performace of an SVM classifier (OVR scheme) for 4 classes, using three different kernel functions. To train and test the SVM classifier we'll have to provide it with the similarity matrices.\n",
    "\n",
    "Training - requires NxN Gram matrix (square matrix compromised of values of the kernel function between pairs training examples)\n",
    "\n",
    "Testing - requires MxN matrix (element i,j is the value of the kernel function between i-th example of the testing set and j-th example of the training set)\n",
    "\n",
    "N = cardinaliry of the training set, M = cardinality of the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(first_dataset, second_dataset, similarity_function, symmetrical=False):\n",
    "    \"\"\"\n",
    "    Calculate the similarity matrix between elements of two datasets using a similarity function.\n",
    "\n",
    "    Args:\n",
    "    - first_dataset: List or array-like, the first dataset\n",
    "    - second_dataset: List or array-like, the second dataset\n",
    "    - similarity_function: Function, the similarity function that takes two elements as arguments\n",
    "\n",
    "    Returns:\n",
    "    - similarity_matrix: NumPy ndarray, the similarity matrix\n",
    "    \"\"\"\n",
    "    if(symmetrical):\n",
    "        size = len(first_dataset)\n",
    "        similarity_matrix = [[0.0] * size for _ in range(size)]\n",
    "\n",
    "        for i in range(size):\n",
    "            for j in range(i, size):\n",
    "                value =similarity_function(first_dataset[i], second_dataset[j])\n",
    "                similarity_matrix[i][j] = value\n",
    "                similarity_matrix[j][i] = value \n",
    "    else:\n",
    "        similarity_matrix = [[similarity_function(x, y) for y in second_dataset] for x in first_dataset]\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering SSK, NGK and WK kernel functions, each with its own set of hiperparameters. \n",
    "\n",
    "SSK is parameterised by $k$ = length of the substrings used for feature mapping/kernel computation and $\\lambda$= real numer from the interval [0,1] which indicates how much we penalise the noncontiguity of the appeared substring in the imput document. \n",
    "\n",
    "NGK is parameterised with $n$, corresponding to $k$ in SSk.\n",
    "\n",
    "WK has no hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def WK_SVM(X_train, y_train, X_test, y_test):  #a multi-class classifier\n",
    "\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using linear tfidf mapping\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, use_idf=True, smooth_idf=True, norm='l2',\n",
    "                                 analyzer='word', stop_words='english')\n",
    "\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    results_df = pd.DataFrame({\n",
    "    'Kernel' : 'WK',\n",
    "    'Class': range(len(precision)),\n",
    "    'F1-Score': f1,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    })\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def NGK_SVM(X_train, y_train, X_test, y_test, k):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using linear n-gram mapping\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the ngrams\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    ngram_range = (k, k)\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=ngram_range)\n",
    "\n",
    "    x_train_ngrams = normalize(vectorizer.fit_transform(X_train), norm='l2')  #ngram vectors normalised to l2 norm\n",
    "    x_test_ngrams = normalize(vectorizer.transform(X_test), norm='l2')\n",
    "\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(x_train_ngrams, y_train)\n",
    "\n",
    "    y_pred = svm_classifier.predict(x_test_ngrams)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'NGK',\n",
    "        'k':k,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import sskpy\n",
    "def ssk(a, b, k, lambd):\n",
    "    return sskpy(a,b,k,lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssk_partial(ka, Lambda):\n",
    "    return lambda a,b: ssk(a,b,k=ka, lambd=Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_SVM(X_train, y_train, X_test, y_test, k, lambd ):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using SSK\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the substrings, lambd= weight decay factor\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k,lambd, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    kernel_function=ssk_partial(k, lambd)\n",
    "    train_matrix=similarity_matrix(X_train, X_train, kernel_function, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, kernel_function)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK',\n",
    "        'k':k,\n",
    "        'lambda': lambd,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.Creating datasets\n",
    "each run has to be repeated 10 times - we need 10 pairs of (train, test) sets that need to satisfy the properties given in the paper:\n",
    "\n",
    " earn 152 (40); acq 114 (25); crude 76 (15); grain 38 (10)\n",
    " since not enough examples of corn I'll use grain as the 4th topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('../data/preprocessed.csv')[['topics', 'body']].copy()\n",
    "topic_mapping = {'earn': 0, 'acq': 1, 'crude': 2, 'grain': 3}\n",
    "data['topics'] = data['topics'].map(topic_mapping)\n",
    "\n",
    "N_classes=3\n",
    "n_per_class=50\n",
    "\n",
    "class0df=data[data.topics==0].head(n_per_class)  #earn\n",
    "class1df=data[data.topics==1].head(n_per_class)  #acq\n",
    "class2df=data[data.topics==2].head(n_per_class)  #crude\n",
    "class3df=data[data.topics==3].head(n_per_class)  #grain\n",
    "\n",
    "final=pd.concat([class0df, class1df, class2df, class3df][:N_classes])\n",
    "print(len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_all=np.array(final['body'])\n",
    "y_all=np.array(final['topics'])\n",
    "\n",
    "n_folds = 5\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "datasets = []\n",
    "\n",
    "for train_index, test_index in stratified_kfold.split(X_all,y_all):\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    \n",
    "    datasets.append((X_train, X_test, y_train, y_test))\n",
    "\n",
    "# datasets[i] = Xtrain_ i , Xtest_i, ytrain_i, ytest_i, i=1,...,10 aka the index of the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Varying Subsequence Length in SSK and NGK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experimet we're keeping lambda for SSK at 0.5, and varying k/n for SSK/NGKin values [3,4,5,6,7,8,10,12], WK has no parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23444/3756035744.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mngk_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNGK_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mssk_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSSK_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_default\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mexperiment_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngk_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mexperiment_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mssk_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23444/2996091970.py\u001b[0m in \u001b[0;36mSSK_SVM\u001b[1;34m(X_train, y_train, X_test, y_test, k, lambd)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# calculate gram matrix for training and matrix for prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mkernel_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mssk_partial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtest_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23444/778496952.py\u001b[0m in \u001b[0;36msimilarity_matrix\u001b[1;34m(first_dataset, second_dataset, similarity_function)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23444/3429591623.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mssk_partial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mka\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mssk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mka\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23444/3544555376.py\u001b[0m in \u001b[0;36mssk\u001b[1;34m(a, b, k, lambd)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msskpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mssk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msskpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambda_default=0.5\n",
    "kvalues=[3,4,5,6,7,8,10,12]\n",
    "\n",
    "experiment_results=[]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    Xtrain, Xtest, ytrain, ytest= datasets[i]\n",
    "\n",
    "    wk_results=WK_SVM(Xtrain,ytrain, Xtest,ytest)\n",
    "    experiment_results.append(wk_results)\n",
    "\n",
    "    for k in kvalues:\n",
    "        ngk_results=NGK_SVM(Xtrain,ytrain, Xtest,ytest,k)\n",
    "        ssk_results=SSK_SVM(Xtrain,ytrain, Xtest,ytest,k, lambda_default)\n",
    "        experiment_results.append(ngk_results)\n",
    "        experiment_results.append(ssk_results)\n",
    "\n",
    "results1=pd.concat(experiment_results)\n",
    "\n",
    "\n",
    "csv_filename=f\"exp1_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results1.to_csv(f\"data/{csv_filename}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Varying Weight Decay Factor in SSK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment we're keeping k/n at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 - Combining two SSK of Different Substring Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 - Combining SSK and NGK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length of both kernels =5, lambda for SSK=0.5, varying the contibutions pf SSK and NKG "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 - Combining two SSK of Different Weight Decay Factors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
