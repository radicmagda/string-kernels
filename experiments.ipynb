{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering performace of an SVM classifier (OVR scheme) for 4 classes, using three different kernel functions. To train and test the SVM classifier we'll have to provide it with the similarity matrices.\n",
    "\n",
    "Training - requires NxN Gram matrix (square matrix compromised of values of the kernel function between pairs training examples)\n",
    "\n",
    "Testing - requires MxN matrix (element i,j is the value of the kernel function between i-th example of the testing set and j-th example of the training set)\n",
    "\n",
    "N = cardinaliry of the training set, M = cardinality of the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(first_dataset, second_dataset, similarity_function):\n",
    "    \"\"\"\n",
    "    Calculate the similarity matrix between elements of two datasets using a similarity function.\n",
    "\n",
    "    Args:\n",
    "    - first_dataset: List or array-like, the first dataset\n",
    "    - second_dataset: List or array-like, the second dataset\n",
    "    - similarity_function: Function, the similarity function that takes two elements as arguments\n",
    "\n",
    "    Returns:\n",
    "    - similarity_matrix: NumPy ndarray, the similarity matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that the datasets are iterable\n",
    "    first_dataset = np.array(first_dataset)\n",
    "    second_dataset = np.array(second_dataset)\n",
    "\n",
    "    # Initialize an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(first_dataset), len(second_dataset)))\n",
    "\n",
    "    # Populate the similarity matrix\n",
    "    for i in range(len(first_dataset)):\n",
    "        for j in range(len(second_dataset)):\n",
    "            similarity_matrix[i, j] = similarity_function(first_dataset[i], second_dataset[j])\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering SSK, NGK and WK kernel functions, each with its own set of hiperparameters. \n",
    "\n",
    "SSK is parameterised by $k$ = length of the substrings used for feature mapping/kernel computation and $\\lambda$= real numer from the interval [0,1] which indicates how much we penalise the noncontiguity of the appeared substring in the imput document. \n",
    "\n",
    "NGK is parameterised with $n$, corresponding to $k$ in SSk.\n",
    "\n",
    "WK has no hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def WK_SWM(X_train, y_train, X_test, y_test):  #a multi-class classifier\n",
    "\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using linear tfidf mapping\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, use_idf=True, smooth_idf=True, norm='l2',\n",
    "                                 analyzer='word', stop_words='english')\n",
    "\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    results_df = pd.DataFrame({\n",
    "    'Kernel' : 'WK',\n",
    "    'Class': range(len(precision)),\n",
    "    'F1-Score': f1,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    })\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def NGK_SVM(X_train, y_train, X_test, y_test, k):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using linear n-gram mapping\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the ngrams\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    ngram_range = (k, k)\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=ngram_range)\n",
    "\n",
    "    x_train_ngrams = normalize(vectorizer.fit_transform(X_train), norm='l2')  #ngram vectors normalised to l2 norm\n",
    "    x_test_ngrams = normalize(vectorizer.transform(X_test), norm='l2')\n",
    "\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(x_train_ngrams, y_train)\n",
    "\n",
    "    y_pred = svm_classifier.predict(x_test_ngrams)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'NGK',\n",
    "        'k':k,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
