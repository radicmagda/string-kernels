{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering performace of an SVM classifier (OVR scheme) for 4 classes, using three different kernel functions. To train and test the SVM classifier we'll have to provide it with the similarity matrices.\n",
    "\n",
    "Training - requires NxN Gram matrix (square matrix compromised of values of the kernel function between pairs training examples)\n",
    "\n",
    "Testing - requires MxN matrix (element i,j is the value of the kernel function between i-th example of the testing set and j-th example of the training set)\n",
    "\n",
    "N = cardinaliry of the training set, M = cardinality of the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(first_dataset, second_dataset, similarity_function, symmetrical=False):\n",
    "    \"\"\"\n",
    "    Calculate the similarity matrix between elements of two datasets using a similarity function.\n",
    "\n",
    "    Args:\n",
    "    - first_dataset: List or array-like, the first dataset\n",
    "    - second_dataset: List or array-like, the second dataset\n",
    "    - similarity_function: Function, the similarity function that takes two elements as arguments\n",
    "\n",
    "    Returns:\n",
    "    - similarity_matrix: NumPy ndarray, the similarity matrix\n",
    "    \"\"\"\n",
    "    cores=os.cpu_count()\n",
    "    if(symmetrical):\n",
    "        size = len(first_dataset)\n",
    "        similarity_matrix = [[0.0] * size for _ in range(size)]\n",
    "\n",
    "        for i in range(size):\n",
    "            for j in range(i, size):\n",
    "                value =similarity_function(first_dataset[i], second_dataset[j])\n",
    "                similarity_matrix[i][j] = value\n",
    "                similarity_matrix[j][i] = value \n",
    "    else:\n",
    "        similarity_matrix = [[similarity_function(x, y) for y in second_dataset] for x in first_dataset]\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering SSK, NGK and WK kernel functions, each with its own set of hiperparameters. \n",
    "\n",
    "SSK is parameterised by $k$ = length of the substrings used for feature mapping/kernel computation and $\\lambda$= real numer from the interval [0,1] which indicates how much we penalise the noncontiguity of the appeared substring in the imput document. \n",
    "\n",
    "NGK is parameterised with $n$, corresponding to $k$ in SSk.\n",
    "\n",
    "WK has no hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def WK_SVM(X_train, y_train, X_test, y_test):  #a multi-class classifier\n",
    "\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using linear tfidf mapping\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, use_idf=True, smooth_idf=True, norm='l2',\n",
    "                                 analyzer='word', stop_words='english')\n",
    "\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    results_df = pd.DataFrame({\n",
    "    'Kernel' : 'WK',\n",
    "    'Class': range(len(precision)),\n",
    "    'F1-Score': f1,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    })\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def NGK_SVM(X_train, y_train, X_test, y_test, k):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using linear n-gram mapping\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the ngrams\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    ngram_range = (k, k)\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=ngram_range)\n",
    "\n",
    "    x_train_ngrams = normalize(vectorizer.fit_transform(X_train), norm='l2')  #ngram vectors normalised to l2 norm\n",
    "    x_test_ngrams = normalize(vectorizer.transform(X_test), norm='l2')\n",
    "\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(x_train_ngrams, y_train)\n",
    "\n",
    "    y_pred = svm_classifier.predict(x_test_ngrams)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'NGK',\n",
    "        'k':k,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import sskpy\n",
    "def ssk(a, b, k, lambd):\n",
    "    if(k==0 or lambd==0):\n",
    "        return 0\n",
    "    else:\n",
    "        return sskpy(a,b,k,lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssk_partial(ka, Lambda):\n",
    "    return lambda a,b: ssk(a,b,k=ka, lambd=Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_SVM(X_train, y_train, X_test, y_test, k, lambd ):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using SSK\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the substrings, lambd= weight decay factor\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k,lambd, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    kernel_function=ssk_partial(k, lambd)\n",
    "    train_matrix=similarity_matrix(X_train, X_train, kernel_function, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, kernel_function)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK',\n",
    "        'k':k,\n",
    "        'lambda': lambd,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.Creating datasets\n",
    "each run has to be repeated 10 times - we need 10 pairs of (train, test) sets that need to satisfy the properties given in the paper:\n",
    "\n",
    " earn 152 (40); acq 114 (25); crude 76 (15); grain 38 (10)\n",
    " since not enough examples of corn I'll use grain as the 4th topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('../data/preprocessed.csv')[['topics', 'body']].copy()\n",
    "topic_mapping = {'earn': 0, 'acq': 1, 'crude': 2, 'grain': 3}\n",
    "data['topics'] = data['topics'].map(topic_mapping)\n",
    "\n",
    "N_classes=4\n",
    "n_per_class=100\n",
    "\n",
    "class0df=data[data.topics==0].head(n_per_class)  #earn\n",
    "class1df=data[data.topics==1].head(n_per_class)  #acq\n",
    "class2df=data[data.topics==2].head(n_per_class)  #crude\n",
    "class3df=data[data.topics==3].head(n_per_class)  #grain\n",
    "\n",
    "final=pd.concat([class0df, class1df, class2df, class3df][:N_classes])\n",
    "print(len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_all=np.array(final['body'])\n",
    "y_all=np.array(final['topics'])\n",
    "\n",
    "n_folds = 5\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "datasets = []\n",
    "\n",
    "for train_index, test_index in stratified_kfold.split(X_all,y_all):\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    \n",
    "    datasets.append((X_train, X_test, y_train, y_test))\n",
    "\n",
    "# datasets[i] = Xtrain_ i , Xtest_i, ytrain_i, ytest_i, i=1,...,10 aka the index of the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Varying Subsequence Length in SSK and NGK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experimet we're keeping lambda for SSK at 0.5, and varying k/n for SSK/NGKin values [3,4,5,6,7,8,10,12], WK has no parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_default=0.5\n",
    "kvalues=[3,4,5,6,7,8,10,12]\n",
    "\n",
    "experiment_results=[]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    Xtrain, Xtest, ytrain, ytest= datasets[i]\n",
    "\n",
    "    wk_results=WK_SVM(Xtrain,ytrain, Xtest,ytest)\n",
    "    experiment_results.append(wk_results)\n",
    "\n",
    "    for k in kvalues:\n",
    "        ngk_results=NGK_SVM(Xtrain,ytrain, Xtest,ytest,k)\n",
    "        ssk_results=SSK_SVM(Xtrain,ytrain, Xtest,ytest,k, lambda_default)\n",
    "        experiment_results.append(ngk_results)\n",
    "        experiment_results.append(ssk_results)\n",
    "\n",
    "results1=pd.concat(experiment_results)\n",
    "\n",
    "\n",
    "csv_filename=f\"exp1_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results1.to_csv(f\"../data/results/original_results/{csv_filename}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Varying Weight Decay Factor in SSK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment we're keeping k/n for SSK/NGK at 5 and varying lambda for SSK trough values [0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_default=5\n",
    "lambdavalues=[0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7]\n",
    "\n",
    "exp2_results=[]\n",
    "\n",
    "for i_exp2 in range(len(datasets)):\n",
    "    Xtrainexp2, Xtestexp2, ytrainexp2, ytestexp2= datasets[i_exp2]\n",
    "\n",
    "    wke2_results=WK_SVM(Xtrainexp2,ytrainexp2, Xtestexp2,ytestexp2)\n",
    "    exp2_results.append(wke2_results)\n",
    "\n",
    "    ngke2_results=NGK_SVM(Xtrainexp2,ytrainexp2, Xtestexp2,ytestexp2,k_default)\n",
    "    exp2_results.append(ngke2_results)\n",
    "\n",
    "    for l in lambdavalues:\n",
    "        sske2_results=SSK_SVM(Xtrainexp2,ytrainexp2, Xtestexp2,ytestexp2,k_default, l)\n",
    "        exp2_results.append(sske2_results)\n",
    "\n",
    "\n",
    "results2=pd.concat(exp2_results)\n",
    "\n",
    "\n",
    "csv2_filename=f\"exp2_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results2.to_csv(f\"../data/results/original_results/{csv2_filename}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  Kernel  Class  F1-Score  Precision  Recall\n",
      "0     WK      0  0.974359   1.000000    0.95\n",
      "1     WK      1  0.952381   0.909091    1.00\n",
      "2     WK      2  0.950000   0.950000    0.95\n",
      "3     WK      3  0.974359   1.000000    0.95,   Kernel  k  Class  F1-Score  Precision  Recall\n",
      "0    NGK  5      0  0.974359   1.000000    0.95\n",
      "1    NGK  5      1  0.952381   0.909091    1.00\n",
      "2    NGK  5      2  0.950000   0.950000    0.95\n",
      "3    NGK  5      3  0.974359   1.000000    0.95,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.01      0  0.950000   0.950000    0.95\n",
      "1    SSK  5    0.01      1  0.517241   0.394737    0.75\n",
      "2    SSK  5    0.01      2  0.514286   0.600000    0.45\n",
      "3    SSK  5    0.01      3  0.296296   0.571429    0.20,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.03      0  0.900000   0.900000    0.90\n",
      "1    SSK  5    0.03      1  0.565217   0.500000    0.65\n",
      "2    SSK  5    0.03      2  0.666667   0.750000    0.60\n",
      "3    SSK  5    0.03      3  0.578947   0.611111    0.55,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.05      0  0.883721   0.826087    0.95\n",
      "1    SSK  5    0.05      1  0.571429   0.545455    0.60\n",
      "2    SSK  5    0.05      2  0.700000   0.700000    0.70\n",
      "3    SSK  5    0.05      3  0.571429   0.666667    0.50,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.07      0  0.904762   0.863636    0.95\n",
      "1    SSK  5    0.07      1  0.488889   0.440000    0.55\n",
      "2    SSK  5    0.07      2  0.702703   0.764706    0.65\n",
      "3    SSK  5    0.07      3  0.444444   0.500000    0.40,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.09      0  0.800000   0.720000    0.90\n",
      "1    SSK  5    0.09      1  0.465116   0.434783    0.50\n",
      "2    SSK  5    0.09      2  0.611111   0.687500    0.55\n",
      "3    SSK  5    0.09      3  0.444444   0.500000    0.40,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.1      0  0.904762   0.863636    0.95\n",
      "1    SSK  5     0.1      1  0.560000   0.466667    0.70\n",
      "2    SSK  5     0.1      2  0.606061   0.769231    0.50\n",
      "3    SSK  5     0.1      3  0.457143   0.533333    0.40,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.3      0  0.775510   0.655172    0.95\n",
      "1    SSK  5     0.3      1  0.652174   0.576923    0.75\n",
      "2    SSK  5     0.3      2  0.580645   0.818182    0.45\n",
      "3    SSK  5     0.3      3  0.529412   0.642857    0.45,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.5      0  0.950000   0.950000    0.95\n",
      "1    SSK  5     0.5      1  0.780488   0.761905    0.80\n",
      "2    SSK  5     0.5      2  0.857143   0.818182    0.90\n",
      "3    SSK  5     0.5      3  0.864865   0.941176    0.80,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.7      0  0.975610   0.952381    1.00\n",
      "1    SSK  5     0.7      1  0.820513   0.842105    0.80\n",
      "2    SSK  5     0.7      2  0.857143   0.818182    0.90\n",
      "3    SSK  5     0.7      3  0.894737   0.944444    0.85,   Kernel  Class  F1-Score  Precision  Recall\n",
      "0     WK      0  0.975610   0.952381    1.00\n",
      "1     WK      1  0.974359   1.000000    0.95\n",
      "2     WK      2  1.000000   1.000000    1.00\n",
      "3     WK      3  1.000000   1.000000    1.00,   Kernel  k  Class  F1-Score  Precision  Recall\n",
      "0    NGK  5      0  0.975610   0.952381    1.00\n",
      "1    NGK  5      1  0.974359   1.000000    0.95\n",
      "2    NGK  5      2  0.974359   1.000000    0.95\n",
      "3    NGK  5      3  0.975610   0.952381    1.00,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.01      0  0.750000   0.642857    0.90\n",
      "1    SSK  5    0.01      1  0.592593   0.470588    0.80\n",
      "2    SSK  5    0.01      2  0.230769   0.500000    0.15\n",
      "3    SSK  5    0.01      3  0.625000   0.833333    0.50,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.03      0  0.765957   0.666667     0.9\n",
      "1    SSK  5    0.03      1  0.585366   0.571429     0.6\n",
      "2    SSK  5    0.03      2  0.533333   0.800000     0.4\n",
      "3    SSK  5    0.03      3  0.666667   0.636364     0.7,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.05      0  0.818182   0.750000    0.90\n",
      "1    SSK  5    0.05      1  0.619048   0.590909    0.65\n",
      "2    SSK  5    0.05      2  0.516129   0.727273    0.40\n",
      "3    SSK  5    0.05      3  0.697674   0.652174    0.75,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.07      0  0.863636   0.791667    0.95\n",
      "1    SSK  5    0.07      1  0.500000   0.500000    0.50\n",
      "2    SSK  5    0.07      2  0.411765   0.500000    0.35\n",
      "3    SSK  5    0.07      3  0.666667   0.636364    0.70,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.09      0  0.755556       0.68    0.85\n",
      "1    SSK  5    0.09      1  0.488889       0.44    0.55\n",
      "2    SSK  5    0.09      2  0.400000       0.60    0.30\n",
      "3    SSK  5    0.09      3  0.650000       0.65    0.65,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.1      0  0.851064   0.740741    1.00\n",
      "1    SSK  5     0.1      1  0.511628   0.478261    0.55\n",
      "2    SSK  5     0.1      2  0.500000   0.666667    0.40\n",
      "3    SSK  5     0.1      3  0.578947   0.611111    0.55,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.3      0  0.826087   0.730769    0.95\n",
      "1    SSK  5     0.3      1  0.727273   0.666667    0.80\n",
      "2    SSK  5     0.3      2  0.580645   0.818182    0.45\n",
      "3    SSK  5     0.3      3  0.820513   0.842105    0.80,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.5      0  0.818182   0.750000    0.90\n",
      "1    SSK  5     0.5      1  0.810811   0.882353    0.75\n",
      "2    SSK  5     0.5      2  0.769231   0.789474    0.75\n",
      "3    SSK  5     0.5      3  0.900000   0.900000    0.90,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.7      0  0.863636   0.791667    0.95\n",
      "1    SSK  5     0.7      1  0.864865   0.941176    0.80\n",
      "2    SSK  5     0.7      2  0.800000   0.800000    0.80\n",
      "3    SSK  5     0.7      3  0.923077   0.947368    0.90,   Kernel  Class  F1-Score  Precision  Recall\n",
      "0     WK      0  0.947368   1.000000    0.90\n",
      "1     WK      1  0.926829   0.904762    0.95\n",
      "2     WK      2  0.950000   0.950000    0.95\n",
      "3     WK      3  0.975610   0.952381    1.00,   Kernel  k  Class  F1-Score  Precision  Recall\n",
      "0    NGK  5      0  0.947368   1.000000     0.9\n",
      "1    NGK  5      1  0.930233   0.869565     1.0\n",
      "2    NGK  5      2  0.947368   1.000000     0.9\n",
      "3    NGK  5      3  0.975610   0.952381     1.0,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.01      0  0.651163   0.608696    0.70\n",
      "1    SSK  5    0.01      1  0.440678   0.333333    0.65\n",
      "2    SSK  5    0.01      2  0.370370   0.714286    0.25\n",
      "3    SSK  5    0.01      3  0.322581   0.454545    0.25,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.03      0  0.680851   0.592593    0.80\n",
      "1    SSK  5    0.03      1  0.425532   0.370370    0.50\n",
      "2    SSK  5    0.03      2  0.470588   0.571429    0.40\n",
      "3    SSK  5    0.03      3  0.562500   0.750000    0.45,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.05      0  0.697674   0.652174    0.75\n",
      "1    SSK  5    0.05      1  0.470588   0.387097    0.60\n",
      "2    SSK  5    0.05      2  0.516129   0.727273    0.40\n",
      "3    SSK  5    0.05      3  0.514286   0.600000    0.45,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.07      0  0.681818   0.625000    0.75\n",
      "1    SSK  5    0.07      1  0.415094   0.333333    0.55\n",
      "2    SSK  5    0.07      2  0.482759   0.777778    0.35\n",
      "3    SSK  5    0.07      3  0.411765   0.500000    0.35,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.09      0  0.595745   0.518519    0.70\n",
      "1    SSK  5    0.09      1  0.480000   0.400000    0.60\n",
      "2    SSK  5    0.09      2  0.370370   0.714286    0.25\n",
      "3    SSK  5    0.09      3  0.555556   0.625000    0.50,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.1      0  0.697674   0.652174    0.75\n",
      "1    SSK  5     0.1      1  0.452830   0.363636    0.60\n",
      "2    SSK  5     0.1      2  0.484848   0.615385    0.40\n",
      "3    SSK  5     0.1      3  0.451613   0.636364    0.35,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.3      0  0.818182   0.750000    0.90\n",
      "1    SSK  5     0.3      1  0.594595   0.647059    0.55\n",
      "2    SSK  5     0.3      2  0.750000   0.750000    0.75\n",
      "3    SSK  5     0.3      3  0.717949   0.736842    0.70,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.5      0  0.923077   0.947368    0.90\n",
      "1    SSK  5     0.5      1  0.904762   0.863636    0.95\n",
      "2    SSK  5     0.5      2  0.947368   1.000000    0.90\n",
      "3    SSK  5     0.5      3  0.975610   0.952381    1.00,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.7      0  0.923077   0.947368    0.90\n",
      "1    SSK  5     0.7      1  0.904762   0.863636    0.95\n",
      "2    SSK  5     0.7      2  0.974359   1.000000    0.95\n",
      "3    SSK  5     0.7      3  0.950000   0.950000    0.95,   Kernel  Class  F1-Score  Precision  Recall\n",
      "0     WK      0  0.947368   1.000000     0.9\n",
      "1     WK      1  0.952381   0.909091     1.0\n",
      "2     WK      2  1.000000   1.000000     1.0\n",
      "3     WK      3  1.000000   1.000000     1.0,   Kernel  k  Class  F1-Score  Precision  Recall\n",
      "0    NGK  5      0  0.947368   1.000000     0.9\n",
      "1    NGK  5      1  0.952381   0.909091     1.0\n",
      "2    NGK  5      2  1.000000   1.000000     1.0\n",
      "3    NGK  5      3  1.000000   1.000000     1.0,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.01      0  0.652174   0.576923    0.75\n",
      "1    SSK  5    0.01      1  0.528302   0.424242    0.70\n",
      "2    SSK  5    0.01      2  0.685714   0.800000    0.60\n",
      "3    SSK  5    0.01      3  0.307692   0.666667    0.20,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.03      0  0.789474   0.833333    0.75\n",
      "1    SSK  5    0.03      1  0.588235   0.483871    0.75\n",
      "2    SSK  5    0.03      2  0.722222   0.812500    0.65\n",
      "3    SSK  5    0.03      3  0.514286   0.600000    0.45,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.05      0  0.700000   0.700000    0.70\n",
      "1    SSK  5    0.05      1  0.583333   0.500000    0.70\n",
      "2    SSK  5    0.05      2  0.810811   0.882353    0.75\n",
      "3    SSK  5    0.05      3  0.514286   0.600000    0.45,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.07      0  0.681818   0.625000    0.75\n",
      "1    SSK  5    0.07      1  0.454545   0.416667    0.50\n",
      "2    SSK  5    0.07      2  0.685714   0.800000    0.60\n",
      "3    SSK  5    0.07      3  0.432432   0.470588    0.40,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.09      0  0.723404   0.629630    0.85\n",
      "1    SSK  5    0.09      1  0.418605   0.391304    0.45\n",
      "2    SSK  5    0.09      2  0.823529   1.000000    0.70\n",
      "3    SSK  5    0.09      3  0.444444   0.500000    0.40,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.1      0  0.695652   0.615385    0.80\n",
      "1    SSK  5     0.1      1  0.478261   0.423077    0.55\n",
      "2    SSK  5     0.1      2  0.742857   0.866667    0.65\n",
      "3    SSK  5     0.1      3  0.424242   0.538462    0.35,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.3      0  0.727273   0.666667    0.80\n",
      "1    SSK  5     0.3      1  0.640000   0.533333    0.80\n",
      "2    SSK  5     0.3      2  0.685714   0.800000    0.60\n",
      "3    SSK  5     0.3      3  0.580645   0.818182    0.45,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.5      0  0.842105   0.888889    0.80\n",
      "1    SSK  5     0.5      1  0.800000   0.720000    0.90\n",
      "2    SSK  5     0.5      2  0.878049   0.857143    0.90\n",
      "3    SSK  5     0.5      3  0.833333   0.937500    0.75,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.7      0  0.888889   1.000000    0.80\n",
      "1    SSK  5     0.7      1  0.808511   0.703704    0.95\n",
      "2    SSK  5     0.7      2  0.878049   0.857143    0.90\n",
      "3    SSK  5     0.7      3  0.888889   1.000000    0.80,   Kernel  Class  F1-Score  Precision  Recall\n",
      "0     WK      0  0.947368   1.000000    0.90\n",
      "1     WK      1  0.930233   0.869565    1.00\n",
      "2     WK      2  0.974359   1.000000    0.95\n",
      "3     WK      3  1.000000   1.000000    1.00,   Kernel  k  Class  F1-Score  Precision  Recall\n",
      "0    NGK  5      0  0.947368   1.000000    0.90\n",
      "1    NGK  5      1  0.930233   0.869565    1.00\n",
      "2    NGK  5      2  0.974359   1.000000    0.95\n",
      "3    NGK  5      3  1.000000   1.000000    1.00,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.01      0  0.697674   0.652174    0.75\n",
      "1    SSK  5    0.01      1  0.542373   0.410256    0.80\n",
      "2    SSK  5    0.01      2  0.357143   0.625000    0.25\n",
      "3    SSK  5    0.01      3  0.666667   1.000000    0.50,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.03      0  0.750000   0.750000    0.75\n",
      "1    SSK  5    0.03      1  0.577778   0.520000    0.65\n",
      "2    SSK  5    0.03      2  0.571429   0.666667    0.50\n",
      "3    SSK  5    0.03      3  0.600000   0.600000    0.60,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.05      0  0.810811   0.882353    0.75\n",
      "1    SSK  5    0.05      1  0.638298   0.555556    0.75\n",
      "2    SSK  5    0.05      2  0.500000   0.562500    0.45\n",
      "3    SSK  5    0.05      3  0.650000   0.650000    0.65,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.07      0  0.864865   0.941176    0.80\n",
      "1    SSK  5    0.07      1  0.636364   0.583333    0.70\n",
      "2    SSK  5    0.07      2  0.578947   0.611111    0.55\n",
      "3    SSK  5    0.07      3  0.634146   0.619048    0.65,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5    0.09      0  0.777778   0.875000    0.70\n",
      "1    SSK  5    0.09      1  0.583333   0.500000    0.70\n",
      "2    SSK  5    0.09      2  0.473684   0.500000    0.45\n",
      "3    SSK  5    0.09      3  0.526316   0.555556    0.50,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.1      0  0.789474   0.833333    0.75\n",
      "1    SSK  5     0.1      1  0.571429   0.482759    0.70\n",
      "2    SSK  5     0.1      2  0.375000   0.500000    0.30\n",
      "3    SSK  5     0.1      3  0.682927   0.666667    0.70,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.3      0  0.820513   0.842105    0.80\n",
      "1    SSK  5     0.3      1  0.695652   0.615385    0.80\n",
      "2    SSK  5     0.3      2  0.702703   0.764706    0.65\n",
      "3    SSK  5     0.3      3  0.789474   0.833333    0.75,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.5      0  0.864865   0.941176    0.80\n",
      "1    SSK  5     0.5      1  0.816327   0.689655    1.00\n",
      "2    SSK  5     0.5      2  0.871795   0.894737    0.85\n",
      "3    SSK  5     0.5      3  0.857143   1.000000    0.75,   Kernel  k  lambda  Class  F1-Score  Precision  Recall\n",
      "0    SSK  5     0.7      0  0.894737   0.944444    0.85\n",
      "1    SSK  5     0.7      1  0.851064   0.740741    1.00\n",
      "2    SSK  5     0.7      2  0.923077   0.947368    0.90\n",
      "3    SSK  5     0.7      3  0.888889   1.000000    0.80]\n",
      "   Kernel  Class  F1-Score  Precision  Recall    k  lambda\n",
      "0      WK      0  0.974359   1.000000    0.95  NaN     NaN\n",
      "1      WK      1  0.952381   0.909091    1.00  NaN     NaN\n",
      "2      WK      2  0.950000   0.950000    0.95  NaN     NaN\n",
      "3      WK      3  0.974359   1.000000    0.95  NaN     NaN\n",
      "0     NGK      0  0.974359   1.000000    0.95  5.0     NaN\n",
      "..    ...    ...       ...        ...     ...  ...     ...\n",
      "3     SSK      3  0.857143   1.000000    0.75  5.0     0.5\n",
      "0     SSK      0  0.894737   0.944444    0.85  5.0     0.7\n",
      "1     SSK      1  0.851064   0.740741    1.00  5.0     0.7\n",
      "2     SSK      2  0.923077   0.947368    0.90  5.0     0.7\n",
      "3     SSK      3  0.888889   1.000000    0.80  5.0     0.7\n",
      "\n",
      "[220 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(exp2_results)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 - Combining two SSK of Different Substring Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we're examining the performance of the SVM classifier using a kernel that is computed as the sum of two SSK with differnt lenths k1 and k2. \n",
    "\n",
    "We're keeping labmda constant for both of those at 0.5 and looking at combinations of lengths in [(3,0),(4,0),(5,0),(6,0),(3,4),(3,5),(3,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_k_comb_SVM(X_train, y_train, X_test, y_test, k1, k2,lambd ):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using SSK\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the substrings, lambd= weight decay factor\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k,lambd, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    kernel1=ssk_partial(k1, lambd)\n",
    "    kernel2=ssk_partial(k2, lambd)\n",
    "    comb= lambda x,y: kernel1(x,y) + kernel2(x,y)\n",
    "    train_matrix=similarity_matrix(X_train, X_train, comb, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, comb)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK k comb',\n",
    "        'k':f\"({k1}, {k2})\",\n",
    "        'lambda': lambd,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_default=0.5\n",
    "k1k2s=[(3,4),(3,5),(3,6),(3,7),(4,5),(4,6),(4,7)]\n",
    "exp3_results=[]\n",
    "\n",
    "for i3 in range(len(datasets)):\n",
    "    Xtrain3, Xtest3, ytrain3, ytest3= datasets[i3]\n",
    "\n",
    "    for k1,k2 in k1k2s:\n",
    "        kcomb_results=SSK_k_comb_SVM(Xtrain3,ytrain3, Xtest3,ytest3,k1,k2, lambda_default)\n",
    "        exp3_results.append(kcomb_results)\n",
    "\n",
    "results3=pd.concat(exp3_results)\n",
    "\n",
    "\n",
    "csv_filename3=f\"exp3_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results3.to_csv(f\"../data/results/original_results/{csv_filename3}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 - Combining SSK and NGK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're examining the performance of the weighted sum of NGK and SSK with same length.\n",
    "\n",
    "Length of both kernels =5, lambda for SSK=0.5, varying the contibutions of NGK and SSK in[(1,0), (0,1), (0.5, 0.5), (0.6,0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def ngk(x,y, trained_vectoriser):\n",
    "    x_ngrams = normalize(trained_vectoriser.transform([x]).toarray(), norm='l2')  \n",
    "    y_ngrams = normalize(trained_vectoriser.transform([y]).toarray(), norm='l2')\n",
    "    return np.dot(x_ngrams.flatten(), y_ngrams.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def SSK_NGK_SVM(X_train, y_train, X_test, y_test, wngk,wssk,k, lambd ):\n",
    "    # define kernel function based on given parameters\n",
    "\n",
    "    sskkernel=ssk_partial(k, lambd)\n",
    "    \n",
    "    if(k !=0):                    \n",
    "        vectorizer = CountVectorizer(analyzer='char', ngram_range=(k,k))\n",
    "        vectorizer.fit(X_train)\n",
    "        ngkkernel=lambda x,y : ngk(x,y,vectorizer)\n",
    "    else:\n",
    "        ngkkernel=lambda x,y : 0\n",
    "\n",
    "    comb= lambda x,y: wssk*sskkernel(x,y) + wngk* ngkkernel(x,y)\n",
    "\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    train_matrix=similarity_matrix(X_train, X_train, comb, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, comb)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK NGK comb',\n",
    "        'wngk, wssk':f\"({wngk}, {wssk})\",\n",
    "        'k': k,\n",
    "        'lambda': lambd,\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/3537538014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mws\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwnwss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mssk_ngk_comb_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSSK_NGK_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk_default\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_default\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mexp4_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mssk_ngk_comb_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/2820314741.py\u001b[0m in \u001b[0;36mSSK_NGK_SVM\u001b[1;34m(X_train, y_train, X_test, y_test, wngk, wssk, k, lambd)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# calculate gram matrix for training and matrix for prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrain_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymmetrical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtest_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/3824072361.py\u001b[0m in \u001b[0;36msimilarity_matrix\u001b[1;34m(first_dataset, second_dataset, similarity_function, symmetrical)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msimilarity_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/2820314741.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mngkkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mcomb\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwssk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msskkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwngk\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mngkkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# calculate gram matrix for training and matrix for prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/2820314741.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'char'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mngkkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mngk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mngkkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/4104278548.py\u001b[0m in \u001b[0;36mngk\u001b[1;34m(x, y, trained_vectoriser)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mngk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrained_vectoriser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx_ngrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrained_vectoriser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0my_ngrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrained_vectoriser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ngrams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ngrams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\magda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\magda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_default=5\n",
    "lambda_default=0.5\n",
    "wnwss=[(1,0), (0,1), (0.5, 0.5), (0.6,0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]\n",
    "exp4_results=[]\n",
    "\n",
    "for i4 in range(len(datasets)):\n",
    "    Xtrain4, Xtest4, ytrain4, ytest4= datasets[i4]\n",
    "\n",
    "    for wn,ws in wnwss:\n",
    "        ssk_ngk_comb_results=SSK_NGK_SVM(Xtrain4,ytrain4, Xtest4, ytest4,wn, ws,k_default, lambda_default)\n",
    "        exp4_results.append(ssk_ngk_comb_results)\n",
    "\n",
    "results4=pd.concat(exp4_results)\n",
    "\n",
    "csv_filename4=f\"exp4_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results4.to_csv(f\"../data/{csv_filename4}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 - Combining two SSK of Different Weight Decay Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here were using a kernel that is a sum of two SSK with different lambdas, and same k=5. \n",
    "The lambda values were varied trough [(0.05,0), (0.5,0), (0.05, 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSK_lambd_comb_SVM(X_train, y_train, X_test, y_test, k, lambd1,lambd2 ):\n",
    "    '''calculates f1, precision, and recall for a SVM classifer using SSK\n",
    "    Args:\n",
    "    - X_train,y_train, X_test, y_test, k=lenthg of the substrings, lambd= weight decay factor\n",
    "    Returns:\n",
    "    - f1, precision, recall: for each of the classes in form of a pandas dataframe w columns Kernel,k,lambd, Class, F1, Precision , Recall\n",
    "    '''\n",
    "    # calculate gram matrix for training and matrix for prediction\n",
    "    kernel1=ssk_partial(k, lambd1)\n",
    "    kernel2=ssk_partial(k, lambd2)\n",
    "    comb= lambda x,y: kernel1(x,y) + kernel2(x,y)\n",
    "    train_matrix=similarity_matrix(X_train, X_train, comb, symmetrical=True)\n",
    "    test_matrix=similarity_matrix(X_test, X_train, comb)\n",
    "\n",
    "    #model - precomputed, trained on the gram matrix\n",
    "    svm_model=SVC(kernel='precomputed')\n",
    "    svm_model.fit(train_matrix, y_train)\n",
    "\n",
    "    #predicting\n",
    "    y_pred=svm_model.predict(test_matrix)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Kernel':'SSK lambda comb',\n",
    "        'k': k,\n",
    "        'lambdas': f'{lambd1},{lambd2}',\n",
    "        'Class': range(len(precision)),\n",
    "        'F1-Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "        })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_default=5\n",
    "l1l2s=[(0.05,0), (0.5,0), (0.05, 0.5)]\n",
    "\n",
    "exp5_results=[]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    Xtrain, Xtest, ytrain, ytest= datasets[i]\n",
    "\n",
    "    for l1,l2 in l1l2s:\n",
    "        lcomb_results=SSK_lambd_comb_SVM(Xtrain,ytrain, Xtest,ytest,k_default,l1,l2)\n",
    "        exp5_results.append(lcomb_results)\n",
    "\n",
    "results5=pd.concat(exp5_results)\n",
    "\n",
    "\n",
    "csv_filename5=f\"exp5_{n_folds}_iterations__{N_classes}_classes__{n_per_class}_in_each_class.csv\"\n",
    "results5.to_csv(f\"../data/{csv_filename5}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the SSK score\n",
    "- the ssk implementation used previously doesn't normalise the vectors, aka doesnt't take into account document length\n",
    "- this results in ssk values being higher for longer documents, without actually having more similarity\n",
    "- to tackle this we'll make a slight change to the kernel function, dividing the score with the length of the longer document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import sskpy\n",
    "def ssk_scaled(a, b, k, lambd):    #accounts for document length\n",
    "    len_a=len(a)\n",
    "    len_b=len(b)\n",
    "    return sskpy(a,b,k,lambd)/(max(len_a, len_b))\n",
    "\n",
    "def ssk_scaled_partial(ka, Lambda):\n",
    "    return lambda a,b: ssk_scaled(a,b,k=ka, lambd=Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovit ćemo eksperimente 1 i "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
